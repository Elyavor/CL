{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Elya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Elya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import pymorphy2\n",
    "import re\n",
    "analyzer = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Анимационный ремейк «Гамлета» Уильяма Шекспира...</td>\n",
       "      <td>Главный мультфильм всех времен и народов (но л...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>А на душе глубокий Шрам</td>\n",
       "      <td>В 1994 году ворвался в мировой кинематограф му...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Король лев — неповторимый шедевр на все времена</td>\n",
       "      <td>Начитавшись положительных отзывов о ремейке Ко...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Мультфильм на все времена!</td>\n",
       "      <td>Я долго откладывал этот мультфильм в долгий ящ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Лучший на свете анимационный фильм</td>\n",
       "      <td>Анимационный фильм 'Король Лев' 1994 года – на...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Анимационный ремейк «Гамлета» Уильяма Шекспира...   \n",
       "1                            А на душе глубокий Шрам   \n",
       "2    Король лев — неповторимый шедевр на все времена   \n",
       "3                         Мультфильм на все времена!   \n",
       "4                 Лучший на свете анимационный фильм   \n",
       "\n",
       "                                         description  \n",
       "0  Главный мультфильм всех времен и народов (но л...  \n",
       "1  В 1994 году ворвался в мировой кинематограф му...  \n",
       "2  Начитавшись положительных отзывов о ремейке Ко...  \n",
       "3  Я долго откладывал этот мультфильм в долгий ящ...  \n",
       "4  Анимационный фильм 'Король Лев' 1994 года – на...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"reviews1.json\", encoding='utf8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wordlist(text, remove_stopwords=False):\n",
    "    # оставляем только буквенные символы, удаляем нечто в скобках\n",
    "    text = re.sub(\"[^а-яА-ЯёЁ]\",\" \", re.sub(r'\\((.*?)\\)', \"\", text))\n",
    "    # токенизируем текст и приводим к нижнему регистру\n",
    "    words = word_tokenize(text)\n",
    "    words = [w.lower() for w in words]\n",
    "    \n",
    "    # удалим лишние части речи\n",
    "    POS_black_list = [\"NUMR\", \"NPRO\", \"PRED\", \"PREP\", \"CONJ\", \"PRCL\", \"INTJ\"]\n",
    "    filter_words = [word for word in words if analyzer.parse(word)[0].tag.POS not in POS_black_list]\n",
    "    \n",
    "    norm_words = [analyzer.parse(word)[0].normal_form for word in words]\n",
    "    if remove_stopwords:\n",
    "        # убираем стоп-слова\n",
    "        stops = stopwords.words(\"russian\") + [\"это\", \"который\", \"наш\", \"мочь\", \"год\", \n",
    "                                            \"такой\", \"знать\", \"мы\", \"свой\", \"один\", \"другой\", \"хотеть\",\n",
    "                                            \"всё\", \"весь\", \"очень\", \"думать\", \"нужно\",\n",
    "                                            \"большой\", \"использовать\", \"говорить\", \"сказать\",\n",
    "                                            \"иметь\", \"сделать\", \"первый\", \"каждый\", \"день\", \"её\", \"ваш\",\n",
    "                                            \"стать\", \"больший\", \"ваше\", \"день\", \"самый\", \"понять\",\n",
    "                                            \"просто\", \"ещё\", \"также\", \"например\"]\n",
    "        norm_words = [w for w in norm_words if w not in stops]\n",
    "    return norm_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"preprocessed_text\"] = df.apply(lambda row: text_to_wordlist(row[\"description\"], remove_stopwords=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Анимационный ремейк «Гамлета» Уильяма Шекспира...</td>\n",
       "      <td>Главный мультфильм всех времен и народов (но л...</td>\n",
       "      <td>[главный, мультфильм, время, народ, производит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>А на душе глубокий Шрам</td>\n",
       "      <td>В 1994 году ворвался в мировой кинематограф му...</td>\n",
       "      <td>[ворваться, мировой, кинематограф, мультиплика...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Король лев — неповторимый шедевр на все времена</td>\n",
       "      <td>Начитавшись положительных отзывов о ремейке Ко...</td>\n",
       "      <td>[начитаться, положительный, отзыв, ремейка, ко...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Мультфильм на все времена!</td>\n",
       "      <td>Я долго откладывал этот мультфильм в долгий ящ...</td>\n",
       "      <td>[долго, откладывать, мультфильм, долгий, ящик,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Лучший на свете анимационный фильм</td>\n",
       "      <td>Анимационный фильм 'Король Лев' 1994 года – на...</td>\n",
       "      <td>[анимационный, фильм, король, левый, взгляд, х...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Анимационный ремейк «Гамлета» Уильяма Шекспира...   \n",
       "1                            А на душе глубокий Шрам   \n",
       "2    Король лев — неповторимый шедевр на все времена   \n",
       "3                         Мультфильм на все времена!   \n",
       "4                 Лучший на свете анимационный фильм   \n",
       "\n",
       "                                         description  \\\n",
       "0  Главный мультфильм всех времен и народов (но л...   \n",
       "1  В 1994 году ворвался в мировой кинематограф му...   \n",
       "2  Начитавшись положительных отзывов о ремейке Ко...   \n",
       "3  Я долго откладывал этот мультфильм в долгий ящ...   \n",
       "4  Анимационный фильм 'Король Лев' 1994 года – на...   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  [главный, мультфильм, время, народ, производит...  \n",
       "1  [ворваться, мировой, кинематограф, мультиплика...  \n",
       "2  [начитаться, положительный, отзыв, ремейка, ко...  \n",
       "3  [долго, откладывать, мультфильм, долгий, ящик,...  \n",
       "4  [анимационный, фильм, король, левый, взгляд, х...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32811"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = []\n",
    "for doc in df[\"preprocessed_text\"].tolist():\n",
    "    all_words.extend(doc)\n",
    "\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "id2word = corpora.Dictionary(df[\"preprocessed_text\"].tolist())\n",
    "texts = df[\"preprocessed_text\"].tolist()\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "lda_model = LdaMulticore(corpus=corpus, id2word=id2word, num_topics=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.021*\"мультфильм\" + 0.015*\"король\" + 0.009*\"левый\" + 0.008*\"симб\" + 0.006*\"фильм\" + 0.005*\"ребёнок\" + 0.005*\"детство\" + 0.005*\"смотреть\" + 0.005*\"хороший\" + 0.005*\"персонаж\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pyLDAvis) (0.33.6)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pyLDAvis) (1.17.4)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pyLDAvis) (1.3.3)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pyLDAvis) (0.25.3)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pyLDAvis) (0.14.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pyLDAvis) (2.10.3)\n",
      "Requirement already satisfied: numexpr in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pyLDAvis) (2.7.0)\n",
      "Requirement already satisfied: pytest in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pyLDAvis) (5.3.2)\n",
      "Requirement already satisfied: future in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: funcy in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pyLDAvis) (1.14)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0; sys_platform == \"win32\" in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pytest->pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pytest->pyLDAvis) (19.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pytest->pyLDAvis) (0.13.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pytest->pyLDAvis) (19.2)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pytest->pyLDAvis) (1.8.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pytest->pyLDAvis) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pytest->pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pytest->pyLDAvis) (8.0.2)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\elya\\appdata\\roaming\\python\\python37\\site-packages (from pytest->pyLDAvis) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\elya\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.6.1->pandas>=0.17.0->pyLDAvis) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from packaging->pytest->pyLDAvis) (2.4.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->pyLDAvis) (0.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 21.1.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем темы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'gensim_models' from 'pyLDAvis' (c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pyLDAvis\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-736128849775>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyLDAvis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgensim_models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'gensim_models' from 'pyLDAvis' (c:\\users\\elya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pyLDAvis\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "from pyLDAvis import gensim_models\n",
    "import pickle \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут была визуализация,но перестала работать :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyLDAvis' has no attribute 'gensim_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-861d7c07f755>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mLDAvis_prepared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mLDAvis_prepared\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pyLDAvis' has no attribute 'gensim_models'"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы было проведено тематическое моделирование (LDA) корпуса текстов. Перед\n",
    "кластеризацией проведена предобработка документов: токенизация, лемматизация, нормализация, удаление стоп-слов, удаление служебных частей речи\n",
    "\n",
    "Оптимальное количество тем равно 1, в противном случае, темы очень похожи, т.к. корпус дейтсвительно представляет собой отзывы о мультфильме \"Король Лев\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
